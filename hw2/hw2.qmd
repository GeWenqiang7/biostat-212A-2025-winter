---
title: "Biostat 212a Homework 2"
subtitle: "Due Feb 8, 2025 @ 11:59PM"
author: "Wenqiang Ge UID:106371961"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  # pdf:
  #   documentclass: article
  #   toc: true
  #   toc-depth: 2
  #   keep-tex: true
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

## ISL Exercise 4.8.1 (10pts)

```{r, echo=FALSE, out.width="100%", fig.align='center'}
knitr::include_graphics("images/clipboard-4077728568.png")
```

```{r, echo=FALSE, out.width="40%", fig.align='center'}
knitr::include_graphics(c("images/clipboard-3304908845.png", "images/clipboard-249183538.png"))
```

------------------------------------------------------------------------

Solution:

![](images/clipboard-2967000257.jpeg){width="660"}

## ISL Exercise 4.8.6 (10pts)

![](images/clipboard-2695304714.png)

------------------------------------------------------------------------

Solution:

![](images/clipboard-3585369922.jpeg){width="666"}

## ISL Exercise 4.8.9 (10pts)

![](images/clipboard-2955947930.png)

------------------------------------------------------------------------

Solution:

![](images/clipboard-3451261091.jpeg){width="675"}

## ISL Exercise 4.8.13 (a)-(i) (50pts)

![](images/clipboard-2962329981.png){width="667"}

![](images/clipboard-3390512393.png){width="661"}

------------------------------------------------------------------------

Solution:

```{r}
library(ISLR2)
library(MASS)

data("Weekly")
# Structure of the dataset
str(Weekly)

```

\(a\)

```{r}
# Numerical summary
summary(Weekly)

# Plot the Volume over time
plot(Weekly$Year, Weekly$Volume, main="Trading Volume Over Time", xlab="Year", ylab="Volume", col="blue", pch=20)

# Boxplot of market return (Today) by Direction
boxplot(Today ~ Direction, data=Weekly, main="Market Return by Direction", ylab="Todayâ€™s Return", col=c("red", "green"))

# Correlation matrix (excluding categorical variables)
cor(Weekly[, -9])  # Exclude the Direction column

```

\(b\)

```{r}
# Fit logistic regression model
logistic_model <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                      data = Weekly, family = binomial)

# Summary of the logistic regression model
summary(logistic_model)
```

$log(\frac{P(Up)}{1-P(Up)})$ = 0.26686âˆ’0.04127 Ã— Lag1+0.05844 Ã— Lag2âˆ’0.01066 Ã— Lag3âˆ’0.02779 Ã— Lag4âˆ’0.01447 Ã— Lag5âˆ’0.02274 Ã— Volume.

Yes, the p-values of Lag1 and Lag3 are less than 0.05, so they are statistically significant.

\(c\)

```{r}
# Predict probabilities
pred_probs <- predict(logistic_model, type="response")

# Convert probabilities to class predictions (threshold = 0.5)
pred_classes <- ifelse(pred_probs > 0.5, "Up", "Down")

# Create confusion matrix
conf_matrix <- table(Predicted = pred_classes, Actual = Weekly$Direction)

# Compute accuracy
accuracy <- mean(pred_classes == Weekly$Direction)

# Print results
print(conf_matrix)
print(paste("Overall accuracy:", round(accuracy, 4)))

```

True Positives (TP) = 557 ; False Positives (FP) = 430 ; True Negatives (TN) = 54 ; False Negatives (FN) = 48

Accuracy= $\frac{TP+TN}{Total Samples} = \frac{557+54}{54+48+430+557}=0.5611$ . This is only slightly better than random guessing (50%).

The model is biased towards predicting "Up", as indicated by the large number of false positives (FP = 430). The model fails to predict "Down" accurately, with only 54 correct "Down" predictions out of 484 actual "Down" instances.

\(d\)

```{r}
# Split the dataset
train <- Weekly$Year < 2009
train_data <- Weekly[train, ]
test_data <- Weekly[!train, ]

# Fit logistic regression using Lag2
logistic_model_lag2 <- glm(Direction ~ Lag2, data=train_data, family=binomial)

# Predict on test data
test_probs <- predict(logistic_model_lag2, newdata=test_data, type="response")

# Convert probabilities to class labels
test_preds <- ifelse(test_probs > 0.5, "Up", "Down")

# Compute confusion matrix
conf_matrix_test <- table(Predicted = test_preds, Actual = test_data$Direction)

# Compute accuracy
test_accuracy <- mean(test_preds == test_data$Direction)

# Print results
print(conf_matrix_test)
print(paste("Test accuracy:", round(test_accuracy, 4)))


```

\(e\)

```{r}
# Fit LDA model
lda_model <- lda(Direction ~ Lag2, data=train_data)

# Predict on test data
lda_preds <- predict(lda_model, newdata=test_data)

# Extract class predictions
lda_classes <- lda_preds$class

# Create confusion matrix
conf_matrix_lda <- table(Predicted = lda_classes, Actual = test_data$Direction)

# Compute accuracy
lda_accuracy <- mean(lda_classes == test_data$Direction)

# Print results
print(conf_matrix_lda)
print(paste("LDA test accuracy:", round(lda_accuracy, 4)))

```

\(f\)

```{r}
# Fit QDA model
qda_model <- qda(Direction ~ Lag2, data=train_data)

# Predict on test data
qda_preds <- predict(qda_model, newdata=test_data)

# Extract class predictions
qda_classes <- qda_preds$class

# Compute confusion matrix
conf_matrix_qda <- table(Predicted = qda_classes, Actual = test_data$Direction)

# Compute accuracy
qda_accuracy <- mean(qda_classes == test_data$Direction)

# Print results
print(conf_matrix_qda)
print(paste("QDA test accuracy:", round(qda_accuracy, 4)))

```

\(g\)

```{r}
library(class)

# Prepare training and test data
train_X <- train_data$Lag2
test_X <- test_data$Lag2
train_Y <- train_data$Direction
test_Y <- test_data$Direction

# Apply KNN with K=1
knn_preds <- knn(train = matrix(train_X), test = matrix(test_X), 
                 cl = train_Y, k = 1)

# Compute confusion matrix
conf_matrix_knn <- table(Predicted = knn_preds, Actual = test_Y)

# Compute accuracy
knn_accuracy <- mean(knn_preds == test_Y)

# Print results
print(conf_matrix_knn)
print(paste("KNN (K=1) test accuracy:", round(knn_accuracy, 4)))

```

\(h\)

```{r}
library(e1071)

# Fit Naive Bayes model
nb_model <- naiveBayes(Direction ~ Lag2, data=train_data)

# Predict on test data
nb_preds <- predict(nb_model, newdata=test_data)

# Compute confusion matrix
conf_matrix_nb <- table(Predicted = nb_preds, Actual = test_data$Direction)

# Compute accuracy
nb_accuracy <- mean(nb_preds == test_data$Direction)

# Print results
print(conf_matrix_nb)
print(paste("Naive Bayes test accuracy:", round(nb_accuracy, 4)))

```

\(i\)

```{r}
# Create a comparison table
model_comparison <- data.frame(
  Model = c("Logistic Regression", "LDA", "QDA", "KNN (K=1)", 
            "Naive Bayes"),
  Accuracy = c(test_accuracy, lda_accuracy, qda_accuracy, 
               knn_accuracy, nb_accuracy)
)

# Print comparison results
print(model_comparison)

```

The Logistic Regression and LDA appear to have the best results on this data, and they both have 0.625 accuracy.

## Bonus question: ISL Exercise 4.8.13 Part (j) (30pts)

![](images/clipboard-698312542.png)

------------------------------------------------------------------------

Solution:

\(j\) Logistic Regression with multiple predictors

```{r}
logistic_model_extended <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                               data=train_data, family=binomial)

# Predictions
test_probs_extended <- predict(logistic_model_extended, newdata=test_data, type="response")
test_preds_extended <- ifelse(test_probs_extended > 0.5, "Up", "Down")

# Confusion Matrix
conf_matrix_logistic_extended <- table(Predicted = test_preds_extended, Actual = test_data$Direction)
logistic_accuracy_extended <- mean(test_preds_extended == test_data$Direction)

print(conf_matrix_logistic_extended)
print(paste("Extended Logistic Regression Accuracy:", round(logistic_accuracy_extended, 4)))

```

Logistic Regression with interaction terms

```{r}
logistic_model_interaction <- glm(Direction ~ Lag2 * Volume, 
                                  data=train_data, family=binomial)

# Predictions
test_probs_interaction <- predict(logistic_model_interaction, 
                                  newdata=test_data, type="response")
test_preds_interaction <- ifelse(test_probs_interaction > 0.5, "Up", "Down")

# Confusion Matrix
conf_matrix_logistic_interaction <- table(Predicted = test_preds_interaction, 
                                          Actual = test_data$Direction)
logistic_accuracy_interaction <- mean(
  test_preds_interaction == test_data$Direction
  )

print(conf_matrix_logistic_interaction)
print(paste("Logistic Regression with Interaction Accuracy:", 
            round(logistic_accuracy_interaction, 4)))


```

LDA with More Predictors

```{r}
library(MASS)
lda_model_extended <- lda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                          data=train_data)

# Predictions
lda_preds_extended <- predict(lda_model_extended, newdata=test_data)$class

# Confusion Matrix
conf_matrix_lda_extended <- table(Predicted = lda_preds_extended, Actual = 
                                    test_data$Direction)
lda_accuracy_extended <- mean(lda_preds_extended == test_data$Direction)

print(conf_matrix_lda_extended)
print(paste("Extended LDA Accuracy:", round(lda_accuracy_extended, 4)))

```

QDA with More Predictors

```{r}
qda_model_extended <- qda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                          data=train_data)

# Predictions
qda_preds_extended <- predict(qda_model_extended, newdata=test_data)$class

# Confusion Matrix
conf_matrix_qda_extended <- table(Predicted = qda_preds_extended, Actual = 
                                    test_data$Direction)
qda_accuracy_extended <- mean(qda_preds_extended == test_data$Direction)

print(conf_matrix_qda_extended)
print(paste("Extended QDA Accuracy:", round(qda_accuracy_extended, 4)))

```

Tuning K for KNN

```{r}
library(class)

# Function to evaluate KNN for different K values
knn_evaluate <- function(k) {
  knn_preds <- knn(train=as.matrix(train_data[, c("Lag2")]), 
                   test=as.matrix(test_data[, c("Lag2")]), 
                   cl=train_data$Direction, k=k)
  
  conf_matrix_knn <- table(Predicted = knn_preds, Actual = test_data$Direction)
  knn_accuracy <- mean(knn_preds == test_data$Direction)
  
  return(list(conf_matrix=conf_matrix_knn, accuracy=knn_accuracy))
}

# Experiment with different values of K
knn_results <- lapply(c(1, 3, 5, 7, 10, 15, 20), knn_evaluate)

# Print results for each K
for (i in 1:length(knn_results)) {
  print(paste("KNN with K =", c(1, 3, 5, 7, 10, 15, 20)[i]))
  print(knn_results[[i]]$conf_matrix)
  print(paste("Accuracy:", round(knn_results[[i]]$accuracy, 4)))
}

```

Naive Bayes with More Predictors

```{r}
library(e1071)
nb_model_extended <- naiveBayes(Direction ~ Lag1 + Lag2 + 
                                  Lag3 + Lag4 + Lag5 + Volume, data=train_data)

# Predictions
nb_preds_extended <- predict(nb_model_extended, newdata=test_data)

# Confusion Matrix
conf_matrix_nb_extended <- table(Predicted = nb_preds_extended, Actual = 
                                   test_data$Direction)
nb_accuracy_extended <- mean(nb_preds_extended == test_data$Direction)

print(conf_matrix_nb_extended)
print(paste("Extended Naive Bayes Accuracy:", round(nb_accuracy_extended, 4)))

```

Comparing All Models

```{r}
# Create a comparison table
model_comparison <- data.frame(
  Model = c("Logistic Regression", "logistic_model_extended", 
            "Logistic Regression (Interaction)", 
            "LDA", "LDA (Extended)", "QDA", "QDA (Extended)", 
            "KNN (K=1)","KNN (K=3)", "KNN (K=5)", "KNN (K=7)", 
            "KNN (K=10)", "KNN (K=15)", "KNN (K=20)", 
            "Naive Bayes", "Naive Bayes (Extended)"),
  Accuracy = c(test_accuracy, logistic_accuracy_extended, 
               logistic_accuracy_interaction, 
               lda_accuracy, lda_accuracy_extended, 
               qda_accuracy, qda_accuracy_extended, 
               knn_results[[1]]$accuracy, knn_results[[2]]$accuracy, 
               knn_results[[3]]$accuracy, knn_results[[4]]$accuracy, 
               knn_results[[5]]$accuracy, knn_results[[6]]$accuracy, 
               knn_results[[7]]$accuracy,
               nb_accuracy, nb_accuracy_extended)
)

# Print comparison results
print(model_comparison)
```

## Bonus question: ISL Exercise 4.8.4 (30pts)

```{r, echo=FALSE, out.width="71%", fig.align='center'}
knitr::include_graphics(("images/clipboard-4051626028.png"))
```

```{r, echo=FALSE, out.width="60%", fig.align='center'}
knitr::include_graphics(("images/clipboard-3443800866.png"))
```

------------------------------------------------------------------------

Solution:

(a)Since the feature $X$ is uniformly distributed in the range$[0,1]$, We consider a test observation and use only those within 10% of its range. If a test point is at $ð‘‹ = 0.6$, we use observations in the range: $[ 0.55 , 0.65]$. The total range is 1 (from 0 to 1), so the fraction of data used is$\frac{selected range}{total range} = \frac{0.65 âˆ’ 0.55}{1} = 0.10$ Therefore, we use 10% of the data.

\(b\)

```{r}

```

\(c\)

```{r}

```

\(d\)

```{r}

```

\(e\)

```{r}

```

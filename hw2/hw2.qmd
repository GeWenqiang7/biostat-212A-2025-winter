---
title: "Biostat 212a Homework 2"
subtitle: "Due Feb 8, 2025 @ 11:59PM"
author: "Wenqiang Ge UID:106371961"
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  # pdf:
  #   documentclass: article
  #   toc: true
  #   toc-depth: 2
  #   keep-tex: true
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
engine: knitr
knitr:
  opts_chunk: 
    fig.align: 'center'
    # fig.width: 6
    # fig.height: 4
    message: FALSE
    cache: false
---

## ISL Exercise 4.8.1 (10pts)

![](images/clipboard-4077728568.png)

![](images/clipboard-3304908845.png)![](images/clipboard-249183538.png)

------------------------------------------------------------------------

Solution:

![](images/clipboard-2967000257.jpeg){width="660"}

## ISL Exercise 4.8.6 (10pts)

![](images/clipboard-2695304714.png)

------------------------------------------------------------------------

Solution:

![](images/clipboard-3585369922.jpeg){width="666"}

## ISL Exercise 4.8.9 (10pts)

![](images/clipboard-2955947930.png)

------------------------------------------------------------------------

Solution:

![](images/clipboard-3451261091.jpeg){width="675"}

## ISL Exercise 4.8.13 (a)-(i) (50pts)

![](images/clipboard-2962329981.png){width="667"}

![](images/clipboard-3390512393.png){width="661"}

------------------------------------------------------------------------

Solution:

```{r}
library(ISLR2)
library(MASS)

data("Weekly")
# Structure of the dataset
str(Weekly)

```

\(a\)

```{r}
# Numerical summary
summary(Weekly)

# Plot the Volume over time
plot(Weekly$Year, Weekly$Volume, main="Trading Volume Over Time", xlab="Year", ylab="Volume", col="blue", pch=20)

# Boxplot of market return (Today) by Direction
boxplot(Today ~ Direction, data=Weekly, main="Market Return by Direction", ylab="Today’s Return", col=c("red", "green"))

# Correlation matrix (excluding categorical variables)
cor(Weekly[, -9])  # Exclude the Direction column

```

\(b\)

```{r}
# Fit logistic regression model
logistic_model <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, 
                      data = Weekly, family = binomial)

# Summary of the logistic regression model
summary(logistic_model)
```

$log(\frac{P(Up)}{1-P(Up)})$ = 0.26686−0.04127 × Lag1+0.05844 × Lag2−0.01066 × Lag3−0.02779 × Lag4−0.01447 × Lag5−0.02274 × Volume.

Yes, the p-values of Lag1 and Lag3 are less than 0.05, so they are statistically significant.

\(c\)

```{r}
# Predict probabilities
pred_probs <- predict(logistic_model, type="response")

# Convert probabilities to class predictions (threshold = 0.5)
pred_classes <- ifelse(pred_probs > 0.5, "Up", "Down")

# Create confusion matrix
conf_matrix <- table(Predicted = pred_classes, Actual = Weekly$Direction)

# Compute accuracy
accuracy <- mean(pred_classes == Weekly$Direction)

# Print results
print(conf_matrix)
print(paste("Overall accuracy:", round(accuracy, 4)))

```

True Positives (TP) = 557 ; False Positives (FP) = 430 ; True Negatives (TN) = 54 ; False Negatives (FN) = 48

Accuracy= $\frac{TP+TN}{Total Samples} = \frac{557+54}{54+48+430+557}=0.5611$ . This is only slightly better than random guessing (50%).

The model is biased towards predicting "Up", as indicated by the large number of false positives (FP = 430). The model fails to predict "Down" accurately, with only 54 correct "Down" predictions out of 484 actual "Down" instances.

\(d\)

```{r}
# Split the dataset
train <- Weekly$Year < 2009
train_data <- Weekly[train, ]
test_data <- Weekly[!train, ]

# Fit logistic regression using Lag2
logistic_model_lag2 <- glm(Direction ~ Lag2, data=train_data, family=binomial)

# Predict on test data
test_probs <- predict(logistic_model_lag2, newdata=test_data, type="response")

# Convert probabilities to class labels
test_preds <- ifelse(test_probs > 0.5, "Up", "Down")

# Compute confusion matrix
conf_matrix_test <- table(Predicted = test_preds, Actual = test_data$Direction)

# Compute accuracy
test_accuracy <- mean(test_preds == test_data$Direction)

# Print results
print(conf_matrix_test)
print(paste("Test accuracy:", round(test_accuracy, 4)))


```

\(e\)

```{r}
# Fit LDA model
lda_model <- lda(Direction ~ Lag2, data=train_data)

# Predict on test data
lda_preds <- predict(lda_model, newdata=test_data)

# Extract class predictions
lda_classes <- lda_preds$class

# Create confusion matrix
conf_matrix_lda <- table(Predicted = lda_classes, Actual = test_data$Direction)

# Compute accuracy
lda_accuracy <- mean(lda_classes == test_data$Direction)

# Print results
print(conf_matrix_lda)
print(paste("LDA test accuracy:", round(lda_accuracy, 4)))

```

\(f\)

```{r}
# Fit QDA model
qda_model <- qda(Direction ~ Lag2, data=train_data)

# Predict on test data
qda_preds <- predict(qda_model, newdata=test_data)

# Extract class predictions
qda_classes <- qda_preds$class

# Compute confusion matrix
conf_matrix_qda <- table(Predicted = qda_classes, Actual = test_data$Direction)

# Compute accuracy
qda_accuracy <- mean(qda_classes == test_data$Direction)

# Print results
print(conf_matrix_qda)
print(paste("QDA test accuracy:", round(qda_accuracy, 4)))

```

\(g\)

```{r}
library(class)

# Prepare training and test data
train_X <- train_data$Lag2
test_X <- test_data$Lag2
train_Y <- train_data$Direction
test_Y <- test_data$Direction

# Apply KNN with K=1
knn_preds <- knn(train = matrix(train_X), test = matrix(test_X), cl = train_Y, k = 1)

# Compute confusion matrix
conf_matrix_knn <- table(Predicted = knn_preds, Actual = test_Y)

# Compute accuracy
knn_accuracy <- mean(knn_preds == test_Y)

# Print results
print(conf_matrix_knn)
print(paste("KNN (K=1) test accuracy:", round(knn_accuracy, 4)))

```

\(h\)

```{r}
library(e1071)

# Fit Naive Bayes model
nb_model <- naiveBayes(Direction ~ Lag2, data=train_data)

# Predict on test data
nb_preds <- predict(nb_model, newdata=test_data)

# Compute confusion matrix
conf_matrix_nb <- table(Predicted = nb_preds, Actual = test_data$Direction)

# Compute accuracy
nb_accuracy <- mean(nb_preds == test_data$Direction)

# Print results
print(conf_matrix_nb)
print(paste("Naive Bayes test accuracy:", round(nb_accuracy, 4)))

```

\(i\)

```{r}
# Create a comparison table
model_comparison <- data.frame(
  Model = c("Logistic Regression", "LDA", "QDA", "KNN (K=1)", "Naive Bayes"),
  Accuracy = c(test_accuracy, lda_accuracy, qda_accuracy, knn_accuracy, nb_accuracy)
)

# Print comparison results
print(model_comparison)

```

The Logistic Regression and LDA appear to have the best results on this data, and they both have 0.625 accuracy.

## Bonus question: ISL Exercise 4.8.13 Part (j) (30pts)

![](images/clipboard-698312542.png)

------------------------------------------------------------------------

Solution:

\(j\)

```{r}

```

## Bonus question: ISL Exercise 4.8.4 (30pts)

![![](images/clipboard-3443800866.png){width="612"}](images/clipboard-4051626028.png){width="645"}

------------------------------------------------------------------------

Solution:
